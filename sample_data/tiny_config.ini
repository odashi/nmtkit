[Global]
forward_memory_mb=256
backward_memory_mb=256
parameter_memory_mb=256
random_seed=12345
backend_random_seed=12345
archive_format=binary

[Corpus]
train_source=sample_data/tiny.in
train_target=sample_data/tiny.out
dev_source=sample_data/tiny.in
dev_target=sample_data/tiny.out
test_source=sample_data/tiny.in
test_target=sample_data/tiny.out

[Model]
source_vocabulary_type=word
target_vocabulary_type=word
source_vocabulary_size=30
target_vocabulary_size=33
encoder_type=bidirectional
decoder_type=default
source_embedding_size=67
target_embedding_size=68
output_embedding_size=69
encoder_hidden_size=63
decoder_hidden_size=64
attention_type=mlp
attention_hidden_size=62

[Batch]
batch_method=target_word
sort_method=target_source
batch_size=32
max_length=16
max_length_ratio=1.5

[Train]
adam_alpha=0.001
adam_beta1=0.9
adam_beta2=0.999
adam_eps=1e-8
max_iteration=1000
evaluation_interval=100
